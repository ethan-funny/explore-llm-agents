{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2e7d6a-e819-454d-9ecd-35530daafe4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9980f3d0-1b66-426a-b890-a3034c854f72",
   "metadata": {},
   "source": [
    "# 0. 简介\n",
    "\n",
    "- 该 notebook 基于 langchain 实现了多种 query 理解技术，包含 RAG Fusion、HyDE 和 IR-CoT 等\n",
    "![](./assets/query理解技术.png)\n",
    "\n",
    "- 各种 query 理解技术的原理，可以参考我写的 RAG 文章系列，扫码关注 👇\n",
    "![](./assets/公众号二维码.png)\n",
    "\n",
    "- 相关实现参考了 https://github.com/langchain-ai/rag-from-scratch\n",
    "\n",
    "## 准备工作\n",
    "\n",
    "- 下载向量模型：代码使用了 [bge-m3](https://huggingface.co/BAAI/bge-m3) 向量模型，请从 huggingface 进行下载\n",
    "- 注册 DeepSeek 开放平台：https://platform.deepseek.com/usage ，注册会送 500 万token\n",
    "    - DeepSeek API 使用与 OpenAI 兼容的 API 格式，因此可以直接使用 langchain 的 openai 接口函数，只需要更改 base_url 和 api_key\n",
    "    - DeepSeek 的接口文档参考：https://platform.deepseek.com/api-docs/zh-cn/\n",
    "    - 根据接口文档，申请 API Key\n",
    "- 安装 python 依赖库\n",
    "    - langchain,langchain-openai,langchain_community,tiktoken,langchainhub,chromadb,beautifulsoup4,unstructured,lxml,sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5c92fa-74d2-4330-8ce9-a6695abab2b2",
   "metadata": {},
   "source": [
    "## 变量设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6688aaeb-ee18-4755-962d-f2a066d31921",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"xxxxxxxxxx\"\n",
    "embedding_model_path = \"/path/to/bge-m3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7953159e-6a17-435c-b004-90904cfd2cca",
   "metadata": {},
   "source": [
    "# 1. Query 改写"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984d074d-2161-41eb-b32e-22358da71290",
   "metadata": {},
   "source": [
    "## 1.1 上下文信息补全"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "260fe50d-c82e-4616-92ce-a007e7d0650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41f2c99e-9b88-4e94-b3c8-b5c030112a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 后续代码也会使用该 llm\n",
    "llm = ChatOpenAI(\n",
    "    model=\"deepseek-chat\", \n",
    "    temperature=0, \n",
    "    api_key=api_key,\n",
    "    base_url=\"https://api.deepseek.com\",\n",
    "    streaming=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "087d4aab-44be-43db-9a35-a0f19bf754f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "使用聊天对话中的上下文重新表述用户问题，使其成为一个独立完整的问题，不要翻译聊天历史和用户问题。\n",
    "<conversation></conversation> 标签中的内容属于聊天对话历史。\n",
    "<question></question> 标签中的内容属于用户的问题。\n",
    "省略开场白，不要解释，根据聊天对话历史和当前用户问题，生成一个独立完整的问题。\n",
    "将独立问题放在 <standalone_question> 标签中。\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "<conversation>\n",
    "User：最近有什么好看的电视剧？\n",
    "Bot：最近上映了《庆余年 2》，与范闲再探庙堂江湖的故事\n",
    "</conversation>\n",
    "\n",
    "<question>\n",
    "User：我想看第一季\n",
    "</question>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e66111a-b513-4e57-bd39-993643de0e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt},\n",
    "]\n",
    "response = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5d52970-4447-47cb-817c-7b0d699690c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<standalone_question>我想知道《庆余年》第一季的观看方式。</standalone_question>', response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 160, 'total_tokens': 185}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_be861a3ed4', 'finish_reason': 'stop', 'logprobs': None}, id='run-96294898-7b09-494e-8915-e25b83439853-0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "876ce4b5-31f2-4e55-a162-1010b2d83fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<standalone_question>我想知道《庆余年》第一季的观看方式。</standalone_question>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae328e5e-9df1-4d6f-aee0-cf354a5fed0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "606fc2f4-946a-49cc-9cbe-25e88927c717",
   "metadata": {},
   "source": [
    "## 1.2 RAG Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "682bb82d-5867-4264-b5bb-b04f26c8544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import UnstructuredHTMLLoader\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c368c589-734a-4993-820a-843ab6ee3d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 加载网页、文本分割、索引构建 ####\n",
    "\n",
    "# 加载 html 文件\n",
    "# 这里以笔者之前写的一篇文章作为查询的知识库 \n",
    "# 原始链接：https://mp.weixin.qq.com/s/37tKVQbxenVVBAeMZ334aQ\n",
    "loader = UnstructuredHTMLLoader(\"example_data/RAG_高效应用指南.html\")\n",
    "data = loader.load()\n",
    "html_content = data[0].page_content\n",
    "\n",
    "# 去除 html 标签，提取文本\n",
    "pattern = re.compile(r'<[^>]+>',re.S)\n",
    "html_source = pattern.sub('', html_content)\n",
    "\n",
    "# 文本递归分割\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=512, \n",
    "    chunk_overlap=64\n",
    ")\n",
    "\n",
    "chunks = text_splitter.create_documents(texts=[html_source])\n",
    "\n",
    "# 向量化\n",
    "hf_embedding = HuggingFaceEmbeddings(model_name=embedding_model_path,\n",
    "                                     encode_kwargs={'normalize_embeddings': True})\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=chunks, \n",
    "                                    embedding=hf_embedding)\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26e8f994-648b-4fbd-805d-713bc8f93176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.load import dumps, loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb25f61b-923d-4325-98a2-c6e9589a343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RRF 融合\n",
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    \"\"\" Reciprocal_rank_fusion that takes multiple lists of ranked documents \n",
    "        and an optional parameter k used in the RRF formula \"\"\"\n",
    "    \n",
    "    # 初始化一个字典来保存每个唯一文档的融合分数\n",
    "    fused_scores = {}\n",
    "\n",
    "    # 遍历每个排名文档的列表\n",
    "    for docs in results:\n",
    "        # 遍历列表中的每个文档及其排名（在列表中的位置）\n",
    "        for rank, doc in enumerate(docs):\n",
    "            # 将文档转换为字符串格式以用作键（假设文档可以序列化为JSON）\n",
    "            doc_str = dumps(doc)\n",
    "            # 如果文档还没有在fused_scores字典中，以0为初始分数添加它\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            # 检索文档的当前分数（如果有）\n",
    "            previous_score = fused_scores[doc_str]\n",
    "            # 使用RRF公式更新文档的分数：1 / (排名 + k)\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "\n",
    "    # 根据他们的融合分数降序排序文档，以获得最终的重排结果\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "\n",
    "    # 将重排结果以元组列表的形式返回，每个元组包含文档和其融合分数\n",
    "    return reranked_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83b7ce77-2bc4-41a4-8060-d2ef8be123a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"你是一个能根据单一输入查询生成多个搜索查询的有用助手。生成3个不同版本的用户问题。\n",
    "原始问题：{question}，输出 3 个不同版本的问题：\"\"\"\n",
    "\n",
    "question = \"文本分块在 RAG 系统中有什么作用\"\n",
    "\n",
    "prompt_rag_fusion = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_rag_fusion \n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")\n",
    "\n",
    "retrieval_chain_rag_fusion = generate_queries | retriever.map() | reciprocal_rank_fusion\n",
    "\n",
    "docs = retrieval_chain_rag_fusion.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b90b93b-c952-4195-85d2-d262b65caa9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95c53dac-a3c9-4b57-8a51-40846110f847",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='•\\xa0提升模型性能：LLM 在处理过长的文本时可能会遇到性能瓶颈。通过将文本分割成较小的片段，可以使模型更有效地处理和理解每一部分，同时也有助于模型根据查询返回更准确的信息。\\n\\n因此，文本分块是很重要的一个环节，在 RAG 的众多环节中，它也许是我们容易做到高质量的一个环节。\\n\\n下面我们来看看有哪些分块的策略。\\n\\n按大小分块'),\n",
       "  0.05),\n",
       " (Document(page_content='另外，为了直观分析文本分割器是如何工作的，我们可以使用\\xa0ChunkViz\\xa0工具进行可视化，它会展示文本是如何被分割的，可以帮助我们调整分割参数。\\n\\n拓展阅读\\n\\n•\\xa0https://python.langchain.com/docs/modules/data_connection/document_transformers/\\n\\n•\\xa0https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb\\n\\n•\\xa0https://arxiv.org/pdf/2312.06648\\n\\n•\\xa0https://chunkviz.up.railway.app/\\n\\n总结\\n\\nRAG 是扩展 LLM 知识边界的利器，本文对 RAG 系统前置的文档解析和文本分块两个环节进行深入了探讨。\\n\\n文档智能理解从各种各样非结构化的文档中提取内容，是构建高质量 RAG 系统的基础。数据质量决定成效。Garbage in, Garbage out. Quality in, Quality out.'),\n",
       "  0.04918032786885246),\n",
       " (Document(page_content='本系列将根据这幅架构图，对其中的重要环节进行深入探讨，提供一系列具有可操作性的方法和建议，从而提高 RAG 系统的整体性能。\\n\\n本文是『RAG 高效应用指南』系列的第 1 篇文章，本文将首先对 RAG 系统前置离线环节的文档解析和文本分块进行深入探讨。\\n\\n拓展阅读\\n\\n•\\xa0https://research.facebook.com/publications/retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks/\\n\\n•\\xa0https://myscale.com/blog/how-does-retrieval-augmented-generation-system-work/\\n\\n•\\xa0https://myscale.com/blog/prompt-engineering-vs-finetuning-vs-rag/\\n\\n文档智能解析'),\n",
       "  0.048131080389144903),\n",
       " (Document(page_content='文本分块将长文本分解为较小的文本块，这些块被嵌入、索引、存储，然后用于后续的检索。文本分块并没有固定的最佳策略，每种策略各有优缺点，关键在于根据具体的需求和场景，灵活运用不同策略，提高搜索准确性与模型性能。\\n\\n预览时标签不可点\\n\\n微信扫一扫\\n\\n关注该公众号\\n\\n继续滑动看下一个\\n\\nAI花果山\\n\\n向上滑动看下一个\\n\\n知道了\\n\\n使用小程序\\n\\n取消\\n\\n允许\\n\\n取消\\n\\n允许\\n\\n视频\\n\\n小程序\\n\\n，轻点两下取消赞\\n\\n在看\\n\\n，轻点两下取消在看\\n\\n分享\\n\\n留言\\n\\n收藏'),\n",
       "  0.016129032258064516),\n",
       " (Document(page_content='知识缓存\\n\\n等环节都会影响系统的性能。\\n\\n『RAG 高效应用指南』系列将就如何提高 RAG 系统性能进行深入探讨，提供一系列具体的方法和建议。同时读者也需要记住，提高 RAG 系统性能是一个持续的过程，需要不断地评估、优化和迭代。\\n\\n本文是『RAG 高效应用指南』系列的第 1 篇文章，本文将首先对 RAG 系统前置离线环节的文档解析和文本分块进行深入探讨。\\n\\nRAG 简介\\n\\n2020 年，Meta AI 研究人员提出了检索增强生成（RAG）的方法，用于提高 LLM 在特定任务上的性能。LLM 擅长语言理解、推理和生成等任务，但也存在一些问题：'),\n",
       "  0.015873015873015872),\n",
       " (Document(page_content='构建一个检索增强生成 (Retrieval-Augmented Generation, RAG)\\xa0应用的概念验证过程相对简单，但要将其推广到生产环境中则会面临多方面的挑战。这主要是因为 RAG 系统涉及多个不同的组件，每个组件都需要精心设计和优化，以确保整体性能达到令人满意的水平。在这一过程中，\\n\\n外部非结构化数据的清洗和处理\\n\\n文本分块\\n\\nQuery 的预处理\\n\\n是不是每次 Query 都要进行检索\\n\\n上下文信息的检索和排序能力\\n\\n如何评估检索生成质量\\n\\n知识缓存\\n\\n等环节都会影响系统的性能。'),\n",
       "  0.015873015873015872)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f50a30d6-e79f-468d-9887-4d1c262377fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "# RAG\n",
    "template = \"\"\"基于以下参考信息回答用户的问题:\n",
    "\n",
    "参考信息：{context}\n",
    "\n",
    "用户问题：{question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain_rag_fusion, \n",
    "     \"question\": itemgetter(\"question\")} \n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "result = final_rag_chain.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b26a8ff1-f4bd-41b3-8d84-1fe7959dd134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文本分块在 RAG（Retrieval-Augmented Generation）系统中的作用主要体现在以下几个方面：\n",
      "\n",
      "1. **提高模型性能**：根据提供的参考信息，文本分块可以帮助大型语言模型（LLM）更有效地处理和理解文本。通过将长文本分解为较小的片段，模型可以更好地处理每一部分，从而提高处理效率和理解准确性（参考信息中的第二条）。\n",
      "\n",
      "2. **优化检索过程**：文本分块后的文本块被嵌入、索引和存储，这有助于后续的检索过程。这种分块策略可以根据具体需求和场景灵活运用，以提高搜索的准确性和模型性能（参考信息中的第五条）。\n",
      "\n",
      "3. **支持动态知识引入**：在RAG系统中，文本分块支持模型动态地引入最新的数据，从而在生成响应时提供更准确、更新的信息。这有助于扩展LLM的知识边界，使其能够访问专属知识库并利用最新的数据（参考信息中的第一条和第六条）。\n",
      "\n",
      "4. **基础数据处理**：文本分块是构建高质量RAG系统的基础之一，它涉及到从各种非结构化文档中提取内容，确保数据质量，这对于系统的整体性能至关重要（参考信息中的第四条）。\n",
      "\n",
      "总结来说，文本分块在RAG系统中是一个关键环节，它通过优化数据处理和检索过程，支持模型更有效地利用和生成信息，从而提高系统的整体性能和响应质量。\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cba143a-daca-4053-8867-905f50880cec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a18f512-5940-45c6-89db-90a0a8e74afd",
   "metadata": {},
   "source": [
    "## 1.3 Multi Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b34e6da-76b5-403d-b927-f0b712a22f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Query: Different Perspectives\n",
    "template = \"\"\"你是一个AI语言模型助手。你的任务是生成3个不同版本的用户问题，以从向量数据库中检索相关文档。\n",
    "通过生成用户问题的多个视角，你的目标是帮助用户克服基于距离的相似性搜索的一些限制。\n",
    "请以换行分隔这些替代问题。 原始问题: {question}\"\"\"\n",
    "\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_perspectives \n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21dd9739-673b-4819-ba94-08c68234a775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='你是一个AI语言模型助手。你的任务是生成3个不同版本的用户问题，以从向量数据库中检索相关文档。\\n通过生成用户问题的多个视角，你的目标是帮助用户克服基于距离的相似性搜索的一些限制。\\n请以换行分隔这些替代问题。 原始问题: {question}'))])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f7de0d2fdd0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f7de0a6c4d0>, model_name='deepseek-chat', temperature=0.0, openai_api_key=SecretStr('**********'), openai_api_base='https://api.deepseek.com', openai_proxy='')\n",
       "| StrOutputParser()\n",
       "| RunnableLambda(...)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc315bd0-ed23-4bfb-be4c-cdee7a51fe17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. 在RAG（Retrieval-Augmented Generation）模型中，文本分块扮演了怎样的角色？',\n",
       " '2. 文本分块技术如何影响RAG系统的性能？',\n",
       " '3. RAG系统中使用文本分块的目的是什么？']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_queries.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b52e4b5-8160-4284-9cec-6fc0ed0910a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_unique_union(documents: list[list]):\n",
    "    \"\"\" Unique union of retrieved docs \"\"\"\n",
    "    # 将列表的列表扁平化，并将每个文档转换为字符串\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "    return [loads(doc) for doc in unique_docs]\n",
    "\n",
    "# Retrieve\n",
    "retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
    "docs = retrieval_chain.invoke({\"question\":question})\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23c4fe7a-d828-4e9a-9dc6-f9eef66c2df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'文本分块在 RAG（Retrieval-Augmented Generation）系统中的作用主要体现在以下几个方面：\\n\\n1. **提高搜索准确性与模型性能**：文本分块将长文本分解为较小的文本块，这些块被嵌入、索引、存储，然后用于后续的检索。这种分解有助于模型更有效地处理和理解每一部分，同时也有助于模型根据查询返回更准确的信息。\\n\\n2. **优化系统性能**：在构建 RAG 应用的过程中，文本分块是前置离线环节的重要组成部分。通过合理的文本分块策略，可以优化系统的整体性能，包括外部非结构化数据的清洗和处理、Query 的预处理、上下文信息的检索和排序能力等。\\n\\n3. **支持知识缓存**：文本分块也有助于知识缓存的有效实施，通过将文本分解成可管理的块，可以更有效地存储和检索相关信息，从而提高系统的响应速度和效率。\\n\\n4. **可视化与调整**：使用工具如 ChunkViz 可以帮助直观分析文本分割器的工作方式，通过可视化文本如何被分割，可以调整分割参数，进一步优化分块策略。\\n\\n综上所述，文本分块在 RAG 系统中是一个关键环节，它通过优化文本处理和检索过程，提高系统的整体性能和准确性。'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RAG\n",
    "template = \"\"\"基于以下参考信息回答用户的问题:\n",
    "\n",
    "参考信息：{context}\n",
    "\n",
    "用户问题：{question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain, \n",
    "     \"question\": itemgetter(\"question\")} \n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d7ebc3-82bd-4c25-a7a8-65b98dffcf7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08575b81-43d0-43ef-bbb0-273438780e73",
   "metadata": {},
   "source": [
    "# 2. Query 增强"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa4d06a-230f-4c84-a45e-9cb8e3e3689a",
   "metadata": {},
   "source": [
    "## 2.1 HyDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90143faf-a027-4c5a-bac7-eec2ebd85e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'文本分块在RAG（Retrieval-Augmented Generation）系统中用于将输入文本分割成适合处理的小段，以便进行有效的信息检索和生成响应。这有助于提高系统的效率和准确性，因为它允许系统更精细地处理和理解文本内容。'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HyDE document genration\n",
    "template = \"\"\"简洁地回答用户的问题。\n",
    "问题: {question}\"\"\"\n",
    "\n",
    "prompt_hyde = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "generate_docs_for_retrieval = (\n",
    "    prompt_hyde | llm | StrOutputParser() \n",
    ")\n",
    "\n",
    "generate_docs_for_retrieval.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96c784c8-a88a-47e1-b705-3e7b6e6aa10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='•\\xa0提升模型性能：LLM 在处理过长的文本时可能会遇到性能瓶颈。通过将文本分割成较小的片段，可以使模型更有效地处理和理解每一部分，同时也有助于模型根据查询返回更准确的信息。\\n\\n因此，文本分块是很重要的一个环节，在 RAG 的众多环节中，它也许是我们容易做到高质量的一个环节。\\n\\n下面我们来看看有哪些分块的策略。\\n\\n按大小分块'), Document(page_content='文本分块将长文本分解为较小的文本块，这些块被嵌入、索引、存储，然后用于后续的检索。文本分块并没有固定的最佳策略，每种策略各有优缺点，关键在于根据具体的需求和场景，灵活运用不同策略，提高搜索准确性与模型性能。\\n\\n预览时标签不可点\\n\\n微信扫一扫\\n\\n关注该公众号\\n\\n继续滑动看下一个\\n\\nAI花果山\\n\\n向上滑动看下一个\\n\\n知道了\\n\\n使用小程序\\n\\n取消\\n\\n允许\\n\\n取消\\n\\n允许\\n\\n视频\\n\\n小程序\\n\\n，轻点两下取消赞\\n\\n在看\\n\\n，轻点两下取消在看\\n\\n分享\\n\\n留言\\n\\n收藏'), Document(page_content='•\\xa0https://arxiv.org/pdf/2111.15664v5\\n\\n•\\xa0https://onechartt.github.io\\n\\n文本分块\\n\\n文本分块（text chunking），或称为文本分割（text splitting），是指将长文本分解为较小的文本块，这些块被嵌入、索引、存储，然后用于后续的检索。通过将大型文档分解成易于管理的部分（如章节、段落，甚至是句子），文本分块可以提高搜索准确性和模型性能。\\n\\n•\\xa0提高搜索准确性：较小的文本块允许基于关键词匹配和语义相似性进行更精确的检索。'), Document(page_content='另外，为了直观分析文本分割器是如何工作的，我们可以使用\\xa0ChunkViz\\xa0工具进行可视化，它会展示文本是如何被分割的，可以帮助我们调整分割参数。\\n\\n拓展阅读\\n\\n•\\xa0https://python.langchain.com/docs/modules/data_connection/document_transformers/\\n\\n•\\xa0https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb\\n\\n•\\xa0https://arxiv.org/pdf/2312.06648\\n\\n•\\xa0https://chunkviz.up.railway.app/\\n\\n总结\\n\\nRAG 是扩展 LLM 知识边界的利器，本文对 RAG 系统前置的文档解析和文本分块两个环节进行深入了探讨。\\n\\n文档智能理解从各种各样非结构化的文档中提取内容，是构建高质量 RAG 系统的基础。数据质量决定成效。Garbage in, Garbage out. Quality in, Quality out.')]\n"
     ]
    }
   ],
   "source": [
    "# 使用生成的假设性回答进行检索\n",
    "retrieval_chain = generate_docs_for_retrieval | retriever \n",
    "retireved_docs = retrieval_chain.invoke({\"question\":question})\n",
    "print(retireved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1147b28-9637-4360-90b1-7e277e87886d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'文本分块在 RAG（Retrieval-Augmented Generation）系统中扮演着至关重要的角色。根据提供的参考信息，文本分块的主要作用包括：\\n\\n1. **提升模型性能**：通过将长文本分割成较小的片段，可以使模型更有效地处理和理解每一部分，这有助于模型根据查询返回更准确的信息。\\n\\n2. **提高搜索准确性**：较小的文本块允许基于关键词匹配和语义相似性进行更精确的检索。这有助于提高搜索的准确性和模型的性能。\\n\\n3. **灵活运用不同策略**：文本分块并没有固定的最佳策略，每种策略各有优缺点。关键在于根据具体的需求和场景，灵活运用不同策略，以提高搜索准确性与模型性能。\\n\\n4. **文档解析和文本分块**：在 RAG 系统中，文档解析和文本分块是前置的重要环节，它们是构建高质量 RAG 系统的基础。数据质量决定成效，因此文本分块的质量直接影响到 RAG 系统的整体性能和输出质量。\\n\\n总结来说，文本分块是 RAG 系统中不可或缺的一环，它通过优化文本处理和检索过程，显著提升了系统的性能和准确性。'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RAG\n",
    "template = \"\"\"基于以下参考信息回答用户的问题:\n",
    "\n",
    "参考信息：{context}\n",
    "\n",
    "用户问题：{question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"context\":retireved_docs,\"question\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8230f5-734a-4bf5-8a4d-4742f612a846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9196a62-1fe7-472a-84b4-6bafd805a710",
   "metadata": {},
   "source": [
    "## 2.2 Step Back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d78e9fcb-8ae7-490b-a8ea-0883e5a9acba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"如何在 Python 中使用 NumPy 计算两个矩阵的点积\",\n",
    "        \"output\": \"如何在 Python 编程中进行矩阵操作\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"如何处理客户的投诉和反馈\",\n",
    "        \"output\": \"如何构建和实施有效的客户服务和反馈机制\",\n",
    "    },\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"你是一位世界知识的专家。你的任务是退一步，将问题改述为更通用、更抽象的问题，这样更容易回答。以下是一些例子：\"\"\",\n",
    "        ),\n",
    "        few_shot_prompt,\n",
    "        (\"user\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e651c33c-8dbe-4aa4-bb94-bd292d35d9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'在信息检索和问答系统中，文本分块的作用是什么？'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_queries_step_back = prompt | llm | StrOutputParser()\n",
    "generate_queries_step_back.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f727e443-df4d-4224-b723-d464116f1e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'文本分块在 RAG（Retrieval-Augmented Generation）系统中扮演着至关重要的角色，主要作用包括：\\n\\n1. **提高模型性能**：通过将长文本分割成较小的片段，LLM（大型语言模型）可以更有效地处理和理解每一部分，避免处理过长文本时的性能瓶颈。这有助于模型更准确地响应查询。\\n\\n2. **提高搜索准确性**：较小的文本块允许基于关键词匹配和语义相似性进行更精确的检索。这使得模型能够根据查询返回更相关和准确的信息。\\n\\n3. **灵活的策略应用**：文本分块并没有固定的最佳策略，每种策略各有优缺点。关键在于根据具体的需求和场景，灵活运用不同策略，如按大小分块、基于内容的分割等，以提高搜索准确性与模型性能。\\n\\n4. **易于管理和优化**：通过将大型文档分解成易于管理的部分（如章节、段落，甚至是句子），文本分块使得文档处理和索引更加高效，便于后续的检索和分析。\\n\\n5. **支持多种分块工具和方法**：如ChunkViz工具可以帮助可视化文本分割过程，调整分割参数；langchain提供的TokenTextSplitter和NLTKTextSplitter等，提供了多种分割方法，以适应不同的应用需求。\\n\\n总之，文本分块是RAG系统中一个关键的环节，它通过优化文本处理和检索过程，显著提升了系统的整体性能和准确性。'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Response prompt \n",
    "response_prompt_template = \"\"\"你是一名世界知识的专家。我将向你提问，你的回答应该是全面的。\n",
    "如果以下背景信息与问题相关，你的回答不应与它们相矛盾。\n",
    "否则，如果它们与问题无关，就忽略它们。\n",
    "\n",
    "# {normal_context}\n",
    "# {step_back_context}\n",
    "\n",
    "# 原始问题: {question}\n",
    "# 回答:\"\"\"\n",
    "response_prompt = ChatPromptTemplate.from_template(response_prompt_template)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"normal_context\": RunnableLambda(lambda x: x[\"question\"]) | retriever,\n",
    "        \"step_back_context\": generate_queries_step_back | retriever,\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "    }\n",
    "    | response_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44360421-dee2-4ea5-b591-f68f11a21c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d45c74b3-a1f9-4973-a9a1-499505e5d859",
   "metadata": {},
   "source": [
    "# 3. Query 分解"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f891a565-5a25-4bb2-8e27-b27cefb3c62b",
   "metadata": {},
   "source": [
    "## 3.1 IR-CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed082cbb-f30b-42ac-b538-ae734b490210",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"你是一个能根据输入问题生成多个子问题的有用助手。\n",
    "目标是将输入分解为一组可以独立回答的子问题。\n",
    "生成与原始问题相关的 3 个子问题。\n",
    "原始问题：{question}。\n",
    "输出 3 个可以独立回答的子问题：\"\"\"\n",
    "\n",
    "prompt_decomposition = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48cb580c-afd1-478d-a804-8c4ba1a775b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1. 什么是文本分块，它在自然语言处理中扮演什么角色？', '2. RAG系统是什么，它如何利用文本分块技术？', '3. 文本分块如何优化RAG系统中的信息检索和生成过程？']\n"
     ]
    }
   ],
   "source": [
    "# Chain\n",
    "generate_queries_decomposition = ( prompt_decomposition | llm | StrOutputParser() | (lambda x: x.split(\"\\n\")))\n",
    "\n",
    "# Run\n",
    "questions = generate_queries_decomposition.invoke({\"question\":question})\n",
    "print(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5ce0684-0812-4f96-83c9-3a3c6214cad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "template = \"\"\"这是你需要回答的问题:\n",
    "\n",
    "\\n --- \\n {question} \\n --- \\n\n",
    "\n",
    "这是任何可用的背景问题和对应的答案:\n",
    "\n",
    "\\n --- \\n {q_a_pairs} \\n --- \\n\n",
    "\n",
    "这是与问题相关的额外背景信息。: \n",
    "\n",
    "\\n --- \\n {context} \\n --- \\n\n",
    "\n",
    "使用上述背景信息以及背景问题和答案对来回答以下问题：\\n {question}\n",
    "\"\"\"\n",
    "\n",
    "decomposition_prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08e2cb90-ca31-449f-945b-a940fa9f1bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_qa_pair(question, answer):\n",
    "    \"\"\"Format Q and A pair\"\"\"\n",
    "    \n",
    "    formatted_string = \"\"\n",
    "    formatted_string += f\"Question: {question}\\nAnswer: {answer}\\n\\n\"\n",
    "    return formatted_string.strip()\n",
    "\n",
    "\n",
    "q_a_pairs = \"\"\n",
    "for q in questions:\n",
    "    \n",
    "    rag_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | retriever, \n",
    "     \"question\": itemgetter(\"question\"),\n",
    "     \"q_a_pairs\": itemgetter(\"q_a_pairs\")} \n",
    "    | decomposition_prompt\n",
    "    | llm\n",
    "    | StrOutputParser())\n",
    "\n",
    "    answer = rag_chain.invoke({\"question\":q,\"q_a_pairs\":q_a_pairs})\n",
    "    q_a_pair = format_qa_pair(q,answer)\n",
    "    q_a_pairs = q_a_pairs + \"\\n---\\n\"+  q_a_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0b75b47-48e4-4626-8521-e7c7482130bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文本分块在RAG系统中优化信息检索和生成过程主要通过以下几个方面：\n",
      "\n",
      "1. **提高检索效率和准确性**：通过将大型文档分解成易于管理的部分（如章节、段落或句子），文本分块允许系统基于关键词匹配和语义相似性进行更精确的检索。这有助于系统快速找到与用户查询最相关的信息，从而提高检索的效率和准确性。\n",
      "\n",
      "2. **优化模型性能**：文本分块有助于提高NLP模型的性能，因为它允许模型处理更小、更集中的数据集。这可以减少计算资源的消耗，并提高处理速度和效率。例如，LLM在处理过长的文本时可能会遇到性能瓶颈，通过将文本分割成较小的片段，可以使模型更有效地处理和理解每一部分，同时也有助于模型根据查询返回更准确的信息。\n",
      "\n",
      "3. **灵活的策略应用**：RAG系统可以根据具体的需求和场景，灵活运用不同的文本分块策略，如按大小分块、语义分块或命题分块等，以提高搜索准确性与模型性能。\n",
      "\n",
      "4. **语义和命题分块**：更高级的分块方法，如语义分块和命题分块，不仅考虑文本的结构，还考虑其语义内容。语义分块首先在句子之间进行分割，然后使用Embedding表征句子，最后将相似的句子组合在一起形成块。命题分块则基于大型语言模型（LLM），逐步构建块，生成独立的陈述或命题，以更精确地捕捉文本的主题和内容。\n",
      "\n",
      "综上所述，文本分块技术在RAG系统中是一个关键步骤，它通过优化文本的组织和处理方式，提高了信息检索的准确性和NLP模型的性能，从而使RAG系统能够更有效地处理和生成与用户查询相关的信息。\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fd267e-d145-407d-b544-7a5e36474b2c",
   "metadata": {},
   "source": [
    "## 3.2 Least-to-Most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e8435295-fd25-4870-9a9d-77fcb8704350",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "你是一个用于回答问题的助手。使用以下检索到的背景信息来回答问题。\n",
    "如果你不知道答案，就说你不知道。\n",
    "最多使用三句话，并保持答案简洁。\\n\n",
    "问题：{question} \\n\n",
    "背景：{context} \\n\n",
    "答案：\n",
    "\"\"\"\n",
    "\n",
    "prompt_rag = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a621996-7067-4c87-983c-859b846cf754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_rag(question,prompt_rag,sub_question_generator_chain):\n",
    "    \"\"\"RAG on each sub-question\"\"\"\n",
    "    \n",
    "    sub_questions = sub_question_generator_chain.invoke({\"question\":question})\n",
    "    \n",
    "    rag_results = []\n",
    "    \n",
    "    for sub_question in sub_questions:\n",
    "        \n",
    "        # 为每个子问题检索文档\n",
    "        retrieved_docs = retriever.get_relevant_documents(sub_question)\n",
    "        \n",
    "        # 在RAG链中使用检索到的文档和子问题\n",
    "        answer = (prompt_rag | llm | StrOutputParser()).invoke({\"context\": retrieved_docs, \n",
    "                                                                \"question\": sub_question})\n",
    "        rag_results.append(answer)\n",
    "    \n",
    "    return rag_results,sub_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8366de99-d885-43a1-ac32-231b142a8f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将检索和RAG过程包装在RunnableLambda中，以便集成到链中\n",
    "answers, questions = retrieve_and_rag(question, prompt_rag, generate_queries_decomposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6fcf0be6-9bda-459e-ac06-2fa229c12a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['文本分块是将长文本分解为较小的文本块的过程，它在自然语言处理中用于提高搜索准确性和模型性能。通过将大型文档分解成易于管理的部分，如章节、段落或句子，文本分块有助于基于关键词匹配和语义相似性进行更精确的检索。',\n",
       "  'RAG系统是一种检索增强生成系统，它通过文本分块技术将长文本分割成较小的片段，以提高模型处理效率和信息检索的准确性。文本分块是RAG系统中的关键环节，有助于从非结构化文档中提取高质量内容。',\n",
       "  '文本分块通过将长文本分割成小片段，提升模型处理效率和信息检索准确性。使用工具如ChunkViz可视化分割过程，帮助调整参数。高质量的文本分块是构建高效RAG系统的基础。'],\n",
       " ['1. 什么是文本分块，它在自然语言处理中扮演什么角色？',\n",
       "  '2. RAG系统是什么，它如何利用文本分块技术？',\n",
       "  '3. 文本分块如何优化RAG系统中的信息检索和生成过程？'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers, questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "269e229e-d65f-42ef-8fc2-058298ab1fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'文本分块在RAG系统中扮演着至关重要的角色。它通过将长文本分割成较小的片段，提高了模型处理效率和信息检索的准确性。这种分割有助于从非结构化文档中提取高质量的内容，是RAG系统中信息检索和生成过程优化的关键环节。通过文本分块，RAG系统能够更有效地处理和利用文本数据，从而提升整体性能。'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_qa_pairs(questions, answers):\n",
    "    \"\"\"Format Q and A pairs\"\"\"\n",
    "    formatted_string = \"\"\n",
    "    for i, (question, answer) in enumerate(zip(questions, answers), start=1):\n",
    "        formatted_string += f\"Question {i}: {question}\\nAnswer {i}: {answer}\\n\\n\"\n",
    "    return formatted_string.strip()\n",
    "\n",
    "\n",
    "context = format_qa_pairs(questions, answers)\n",
    "\n",
    "# Prompt\n",
    "template = \"\"\"这是一组问题和答案对:\n",
    "\n",
    "{context}\n",
    "\n",
    "使用这些来合成对问题的答案。\n",
    "问题: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"context\":context,\"question\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9ee7e4-8998-41f2-b882-a2a679f2fdfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81b5ddfc-22ed-46bc-83a3-50bfd3b8e959",
   "metadata": {},
   "source": [
    "# 附录\n",
    "\n",
    "- LangChain OpenAI 接口使用\n",
    "\n",
    "    - 接口文档\n",
    "        - https://api.python.langchain.com/en/latest/llms/langchain_openai.llms.base.OpenAI.html\n",
    "        - https://api.python.langchain.com/en/latest/chat_models/langchain_openai.chat_models.base.ChatOpenAI.\n",
    "\n",
    "    - 使用例子\n",
    "        - https://python.langchain.com/v0.2/docs/integrations/chat/openai/\n",
    "        - https://python.langchain.com/v0.2/docs/integrations/llms/openai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561de509-49be-44ac-94b7-244ac21cc9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "common_rag",
   "language": "python",
   "name": "common_rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
